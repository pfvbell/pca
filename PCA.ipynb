{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will build several classification models to distinguish between two related classes of cancer, acute lymphoblastic leukemia (ALL) and acute myeloid leukemia (AML), using gene expression measurements. Each row in this file corresponds to a tumor tissue sample from a patient with one of the two forms of leukemia. \n",
    "\n",
    "The first column contains Cancer_type: 0 = ALL class and 1 = AML class\n",
    "Columns 2-7130 contain expression levels of 7129 genes recorded from each tissue sample\n",
    "The last column Cancer_subtype additionally distinguishes between two subtypes of ALL, subtype T and subtype B (used in problem 5): 0 = ALL subtype T, 1 = ALL subtype B, 2 = type AML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(109)\n",
    "#zf = zipfile.ZipFile('data/hw5_genes_multiclass.csv.zip') \n",
    "df = pd.read_csv('/Users/phili/hw5_genes_multiclass.csv')\n",
    "X = df.drop(['Cancer_type','Cancer_subtype'], axis=1)\n",
    "X_train, X_test, y_train, y_test, y2_train, y2_test  = train_test_split(\n",
    "    X, df.Cancer_type, df.Cancer_subtype, test_size=0.25, random_state = 109,\n",
    "    stratify = df.Cancer_subtype)\n",
    "\n",
    "print(df.shape)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "print(df.Cancer_type.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = (X_train - X_train.min())/(X_train.max() - X_train.min()) \n",
    "x_test = (X_test - X_train.min())/(X_train.max() - X_train.min()) \n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = []\n",
    "for column in x_train.columns:\n",
    "    correlations.append(np.corrcoef(x_train[column], y_train)[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_names = []\n",
    "abs_correlations = list(map(abs, correlations))\n",
    "sorted_list = sorted(abs_correlations)\n",
    "top_10 = sorted_list[-10:]\n",
    "for num in top_10:\n",
    "    index = abs_correlations.index(num)\n",
    "    top_names.append(x_train.columns[index])\n",
    "print(f'The top 10 predictors based on simple correlations are: {top_names[0:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_num = max(top_10)\n",
    "best_num_index = top_10.index(best_num)\n",
    "best_predictor = top_names[best_num_index]\n",
    "print(f'The best predictor based on simple correlations is {best_predictor}')\n",
    "\n",
    "new_df = x_train\n",
    "new_df['cancer'] = y_train.values\n",
    "new_df_test = x_test\n",
    "new_df_test['cancer'] = y_test.values\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(new_df[new_df['cancer'] == 1].X95735_at, bins = 100, stacked=True, density = True, label='AML')\n",
    "plt.hist(new_df[new_df['cancer'] == 0].X95735_at, bins = 100, stacked=True, density = True, label='ALL')\n",
    "plt.title('Distribution of X95735_at in Training set')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(new_df_test[new_df_test['cancer'] == 1].X95735_at, bins=50, stacked=True, density = True, label='AML')\n",
    "plt.hist(new_df_test[new_df_test['cancer'] == 0].X95735_at, bins=50, stacked=True, density = True, label='ALL')\n",
    "plt.title('Distribution of X95735_at in Test set')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_list = []\n",
    "cancer_list_test = []\n",
    "for rows in range(0, 564):\n",
    "    if new_df['X95735_at'].values[rows] > 0.4:\n",
    "        cancer_list.append(0)\n",
    "    else:\n",
    "        cancer_list.append(1)\n",
    "\n",
    "for rows in range(len(new_df_test)):\n",
    "    if new_df_test['X95735_at'].values[rows] > 0.4:\n",
    "        cancer_list_test.append(0)\n",
    "    else:\n",
    "        cancer_list_test.append(1)\n",
    "        \n",
    "train_score = round(accuracy_score(y_train, cancer_list),3)\n",
    "test_score = round(accuracy_score(y_test, cancer_list_test),3)\n",
    "print('0.4 will be used as a classification threshold.')\n",
    "print(f'The train score is {train_score}')\n",
    "print(f'The test score is {test_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Model - Single Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_train[[best_predictor]]\n",
    "y = y_train\n",
    "x_t = x_test[[best_predictor]]\n",
    "y_t = y_test\n",
    "\n",
    "logit1 = LogisticRegression(penalty='none', max_iter = 1000)\n",
    "\n",
    "logit1.fit(x,y)\n",
    "\n",
    "train_accuracy = logit1.score(x, y)\n",
    "test_accuracy = logit1.score(x_t, y_t)\n",
    "print(f'The train accuracy for Logit 1 is {round(train_accuracy,3)}')\n",
    "print(f'The test accuracy for Logit 1 is {round(test_accuracy, 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with all predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = x_train.columns\n",
    "x = x_train\n",
    "y = y_train\n",
    "x_t = x_test\n",
    "y_t = y_test\n",
    "\n",
    "logit2 = LogisticRegression(penalty='none', max_iter = 1000)\n",
    "\n",
    "logit2.fit(x,y)\n",
    "\n",
    "train_accuracy = logit2.score(x, y)\n",
    "test_accuracy = logit2.score(x_t, y_t)\n",
    "print(f'The train accuracy for Logit 2 is {round(train_accuracy,3)}')\n",
    "print(f'The test accuracy for Logit 2 is {round(test_accuracy, 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficients between the two models disagree. This suggests that there may some covariance between the genes in the dataset. It may be the case that other genes covary with the best predictor and therefore some of the predictive power of the best predictor is removed in the multiple logistic regression because there are so many other predictors. \n",
    "\n",
    "Indeed, because the multiple logistic regression involves significant overfitting, it becomes difficult to interpret the coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularised Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = [1e-4,1e-3,1e-2,1e-1,1e0,1e1,1e2,1e3,1e4]\n",
    "cv = 5\n",
    "penalty = 'l1'\n",
    "solver = 'liblinear'\n",
    "\n",
    "logit_lasso = LogisticRegressionCV(\n",
    "    Cs=Cs, cv=cv, penalty=penalty, solver='liblinear'\n",
    ").fit(x, y)\n",
    "\n",
    "logit_lasso_score_train = round(logit_lasso.score(x, y),3)\n",
    "logit_lasso_score_test = round(logit_lasso.score(x_t, y_t), 3)\n",
    "\n",
    "print('The train accuracy is', logit_lasso_score_train)\n",
    "print('The test accuracy is', logit_lasso_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_coefs = list(logit_lasso.coef_[0])\n",
    "lasso_coefs_abs = list(map(abs, lasso_coefs))\n",
    "sorted_coefs = sorted(lasso_coefs_abs)\n",
    "important_coefs = sorted_coefs[-200:]\n",
    "most_important_coefs = [i for i in important_coefs if i > 0]\n",
    "num_important_predictors = len(most_important_coefs)\n",
    "print(f'There are {num_important_predictors} predictors with a coefficient over 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scale_transformer = StandardScaler(copy=True).fit(x_train)\n",
    "x_train_scaled = scale_transformer.transform(x_train)\n",
    "x_test_scaled = scale_transformer.transform(x_test)\n",
    "\n",
    "pca = PCA().fit(x_train_scaled)\n",
    "\n",
    "# transforming the dataframe\n",
    "x_train_pca = pca.transform(x_train_scaled)\n",
    "x_test_pca = pca.transform(x_test_scaled)\n",
    "\n",
    "print('Dimensions of transformed x_train:', x_train_pca.shape)\n",
    "print('Dimensions of transformed x_test', x_test_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['r','c']\n",
    "label_text = [\"ALL\", \"AHL\"]\n",
    "\n",
    "# and we loop over the different groups\n",
    "for cur_quality in [0,1]:\n",
    "    cur_df = x_train_pca[y_train==cur_quality]\n",
    "    plt.scatter(cur_df[:,0], cur_df[:,1], c = colors[cur_quality], label=label_text[cur_quality])\n",
    "\n",
    "# all plots need labels\n",
    "plt.xlabel(\"PCA Dimension 1\")\n",
    "plt.ylabel(\"PCA Dimention 2\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualising using PCA allows us to visualise high-dimensional space in low-dimensional space. It would be very difficult to visualise 7129 dimensions, however using PCA we can visualise high-dimensional datasets. This gives a much faster understanding of the nature of the way in which predictors can distinguish between the two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_2_variance_expl = pca.explained_variance_ratio_[0:1]\n",
    "v_expl = round(pca_2_variance_expl[0],3)\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(20,6))\n",
    "ax1,ax2 = ax.ravel()\n",
    "\n",
    "ratio = pca.explained_variance_ratio_\n",
    "ax1.bar(range(len(ratio)), ratio, color='blue', alpha=0.8)\n",
    "ax1.plot(range(1,len(ratio)+1), ratio, 'o-')\n",
    "ax1.set_ylabel('Explained Variance Ratio')\n",
    "ax1.set_title('Explained Variance Ratio PCA', fontsize=20)\n",
    "ax1.set_xlabel('PCA');\n",
    "\n",
    "ratio = pca.explained_variance_ratio_\n",
    "ax2.plot(range(1,len(ratio)+1), np.cumsum(ratio), 'o-')\n",
    "ax2.set_title('Cumulative Sum of Explained Variance Ratio PCA', fontsize=20)\n",
    "ax2.set_ylabel('Cumulative Sum of Explained Variance Ratio');\n",
    "ax2.set_xlabel('PCA');\n",
    "\n",
    "print('Roughly 250 PCs are needed to explain 90% of the variability in the predictors')\n",
    "print(f'The amount of variance in predictors explained by the first two principal components is {v_expl}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression + PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I cycle through models using increasing numbers of principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using 2 PCs\n",
    "pca_2 = PCA(n_components=2).fit(x_train_scaled)\n",
    "x_train_pca_2 = pca_2.transform(x_train_scaled)\n",
    "x_test_pca_2 = pca_2.transform(x_test_scaled)\n",
    "\n",
    "print('Original dimensions:', x_train_scaled.shape)\n",
    "print('PCA dimensions:     ', x_train_pca_2.shape)\n",
    "\n",
    "#Training a logistic regression model\n",
    "logistic_pca_2 = LogisticRegression(C=100).fit(x_train_pca_2, y_train)\n",
    "\n",
    "#Predict\n",
    "y_pred_train = logistic_pca_2.predict(x_train_pca_2)\n",
    "y_pred_test = logistic_pca_2.predict(x_test_pca_2)\n",
    "\n",
    "#Perfromance Evaluation\n",
    "train_score = accuracy_score(y_train, y_pred_train)*100\n",
    "test_score = accuracy_score(y_test, y_pred_test)*100\n",
    "print(\"Training Set Accuracy:\",str(train_score)+'%')\n",
    "print(\"Testing Set Accuracy:\",str(test_score)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using 50 PCs\n",
    "pca_50 = PCA(n_components=50).fit(x_train_scaled)\n",
    "x_train_pca_2 = pca_50.transform(x_train_scaled)\n",
    "x_test_pca_2 = pca_50.transform(x_test_scaled)\n",
    "\n",
    "print('Original dimensions:', x_train_scaled.shape)\n",
    "print('PCA dimensions:     ', x_train_pca_2.shape)\n",
    "\n",
    "#Training a logistic regression model\n",
    "logistic_pca_2 = LogisticRegression(C=100, max_iter=500).fit(x_train_pca_2, y_train)\n",
    "\n",
    "#Predict\n",
    "y_pred_train = logistic_pca_2.predict(x_train_pca_2)\n",
    "y_pred_test = logistic_pca_2.predict(x_test_pca_2)\n",
    "\n",
    "#Perfromance Evaluation\n",
    "train_score = accuracy_score(y_train, y_pred_train)*100\n",
    "test_score = accuracy_score(y_test, y_pred_test)*100\n",
    "print(\"Training Set Accuracy:\",str(train_score)+'%')\n",
    "print(\"Testing Set Accuracy:\",str(test_score)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using 250 PCs\n",
    "pca_250 = PCA(n_components=250).fit(x_train_scaled)\n",
    "x_train_pca_2 = pca_250.transform(x_train_scaled)\n",
    "x_test_pca_2 = pca_250.transform(x_test_scaled)\n",
    "\n",
    "print('Original dimensions:', x_train_scaled.shape)\n",
    "print('PCA dimensions:     ', x_train_pca_2.shape)\n",
    "\n",
    "#Training a logistic regression model\n",
    "logistic_pca_2 = LogisticRegression(C=100, max_iter=10000).fit(x_train_pca_2, y_train)\n",
    "\n",
    "#Predict\n",
    "y_pred_train = logistic_pca_2.predict(x_train_pca_2)\n",
    "y_pred_test = logistic_pca_2.predict(x_test_pca_2)\n",
    "\n",
    "#Perfromance Evaluation\n",
    "train_score = accuracy_score(y_train, y_pred_train)*100\n",
    "test_score = accuracy_score(y_test, y_pred_test)*100\n",
    "print(\"Training Set Accuracy:\",str(train_score)+'%')\n",
    "print(\"Testing Set Accuracy:\",str(test_score)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the accuracy on the testing set improves with an increase in PCAs from 2 to 50, however, decreases with use of 250 PCAs. The training set accuracy also increases with an increased number of PCs from 2 to 50. The training set, however, reaches 100% accuracy with 250 PCs, which suggests overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use cross-validation to calculate the best number of principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using 2 PCs and CV\n",
    "pca_2_cv = PCA(n_components=2).fit(x_train_scaled)\n",
    "x_train_pca_2 = pca_2_cv.transform(x_train_scaled)\n",
    "x_test_pca_2 = pca_2_cv.transform(x_test_scaled)\n",
    "\n",
    "#Training a logistic regression model\n",
    "logistic_pca_2 = LogisticRegressionCV(max_iter=1000, cv=10).fit(x_train_pca_2, y_train)\n",
    "\n",
    "#Predict\n",
    "y_pred_train = logistic_pca_2.predict(x_train_pca_2)\n",
    "y_pred_test = logistic_pca_2.predict(x_test_pca_2)\n",
    "\n",
    "#Perfromance Evaluation\n",
    "train_score = accuracy_score(y_train, y_pred_train)*100\n",
    "test_score = accuracy_score(y_test, y_pred_test)*100\n",
    "print(\"Training Set Accuracy:\",str(train_score)+'%')\n",
    "print(\"Testing Set Accuracy:\",str(test_score)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using 50 PCs and CV\n",
    "pca_50 = PCA(n_components=50).fit(x_train_scaled)\n",
    "x_train_pca_2 = pca_50.transform(x_train_scaled)\n",
    "x_test_pca_2 = pca_50.transform(x_test_scaled)\n",
    "\n",
    "\n",
    "#Training a logistic regression model\n",
    "logistic_pca_2 = LogisticRegressionCV(max_iter=1000, cv=10).fit(x_train_pca_2, y_train)\n",
    "\n",
    "#Predict\n",
    "y_pred_train = logistic_pca_2.predict(x_train_pca_2)\n",
    "y_pred_test = logistic_pca_2.predict(x_test_pca_2)\n",
    "\n",
    "#Perfromance Evaluation\n",
    "train_score = accuracy_score(y_train, y_pred_train)*100\n",
    "test_score = accuracy_score(y_test, y_pred_test)*100\n",
    "print(\"Training Set Accuracy:\",str(train_score)+'%')\n",
    "print(\"Testing Set Accuracy:\",str(test_score)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using 250 PCs and cv\n",
    "pca_250 = PCA(n_components=250).fit(x_train_scaled)\n",
    "x_train_pca_2 = pca_250.transform(x_train_scaled)\n",
    "x_test_pca_2 = pca_250.transform(x_test_scaled)\n",
    "\n",
    "#Training a logistic regression model\n",
    "logistic_pca_2 = LogisticRegressionCV(max_iter=10000, cv=10).fit(x_train_pca_2, y_train)\n",
    "\n",
    "#Predict\n",
    "y_pred_train = logistic_pca_2.predict(x_train_pca_2)\n",
    "y_pred_test = logistic_pca_2.predict(x_test_pca_2)\n",
    "\n",
    "#Perfromance Evaluation\n",
    "train_score = accuracy_score(y_train, y_pred_train)*100\n",
    "test_score = accuracy_score(y_test, y_pred_test)*100\n",
    "print(\"Training Set Accuracy:\",str(train_score)+'%')\n",
    "print(\"Testing Set Accuracy:\",str(test_score)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using 500 PCs and cv\n",
    "pca_500 = PCA(n_components=500).fit(x_train_scaled)\n",
    "x_train_pca_2 = pca_500.transform(x_train_scaled)\n",
    "x_test_pca_2 = pca_500.transform(x_test_scaled)\n",
    "\n",
    "#Training a logistic regression model\n",
    "logistic_pca_2 = LogisticRegressionCV(max_iter=10000, cv=10).fit(x_train_pca_2, y_train)\n",
    "\n",
    "#Predict\n",
    "y_pred_train = logistic_pca_2.predict(x_train_pca_2)\n",
    "y_pred_test = logistic_pca_2.predict(x_test_pca_2)\n",
    "\n",
    "#Perfromance Evaluation\n",
    "train_score = accuracy_score(y_train, y_pred_train)*100\n",
    "test_score = accuracy_score(y_test, y_pred_test)*100\n",
    "print(\"Training Set Accuracy:\",str(train_score)+'%')\n",
    "print(\"Testing Set Accuracy:\",str(test_score)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This suggests that I may have got the number of PCs that explain 90% accuracy wrong. The accuracy is not increasing if more than 250 PCs are used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use multinomial logistic regression models to predict cancer subtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ridge-like Multinomial with 2 PCs\n",
    "pca = PCA(n_components=2).fit(x_train_scaled)\n",
    "x_train_1 = pca.transform(x_train_scaled)\n",
    "x_test_1 = pca.transform(x_test_scaled)\n",
    "\n",
    "logit_ridge = LogisticRegression(multi_class='multinomial', max_iter=1000)\n",
    "logit_ridge.fit(x_train_1,y2_train) \n",
    "                                 \n",
    "y_pred_train = logit_ridge.predict(x_train_1)\n",
    "y_pred_test = logit_ridge.predict(x_test_1)\n",
    "\n",
    "train_score = accuracy_score(y2_train, y_pred_train)*100\n",
    "test_score = accuracy_score(y2_test, y_pred_test)*100\n",
    "print(\"Training Set Accuracy:\",str(train_score)+'%')\n",
    "print(\"Testing Set Accuracy:\",str(test_score)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ridge-line Multinomial + Quadratic and interaction terms\n",
    "pca = PCA(n_components=2).fit(x_train_scaled)\n",
    "x_train = pca.transform(x_train_scaled)\n",
    "x_test = pca.transform(x_test_scaled)\n",
    "\n",
    "x_train = PolynomialFeatures(degree=2,include_bias=False).fit_transform(x_train)\n",
    "x_test = PolynomialFeatures(degree=2,include_bias=False).fit_transform(x_test)\n",
    "\n",
    "#pca_train_df = pd.DataFrame(x_train, columns=[['PCA1' , 'PCA2']])\n",
    "\n",
    "#pca_train_df['interaction'] = np.sum(pca_train_df['PCA1'] * pca_train_df['PCA2'])\n",
    "#pca_train_df['quad_1'] = np.sum(pca_train_df[['PCA1']] ** 2)\n",
    "#pca_train_df['quad_2'] = np.sum(pca_train_df[['PCA2']] ** 2)\n",
    "\n",
    "#pca_test_df[['interaction']] = np.sum(pca_test_df[['PCA1']] * pca_test_df[['PCA2']])\n",
    "#pca_test_df[['quad_1']] = np.sum(pca_test_df[['PCA1']] ** 2)\n",
    "#pca_test_df[['quad_2']] = np.sum(pca_test_df[['PCA2']] ** 2)\n",
    "\n",
    "logit_ridge_i = LogisticRegression(multi_class='multinomial', max_iter=1000)\n",
    "logit_ridge_i.fit(x_train,y2_train) \n",
    "#logit_ridge_i.fit(pca_train_df[['PCA1','PCA2', 'interaction', 'quad_1', 'quad_2']],y2_train) \n",
    "                                 \n",
    "y_pred_train = logit_ridge_i.predict(x_train)\n",
    "y_pred_test = logit_ridge_i.predict(x_test)\n",
    "\n",
    "train_score = accuracy_score(y2_train, y_pred_train)*100\n",
    "test_score = accuracy_score(y2_test, y_pred_test)*100\n",
    "print(\"Training Set Accuracy:\",str(train_score)+'%')\n",
    "print(\"Testing Set Accuracy:\",str(test_score)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot decision boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_test_df = pd.DataFrame(x_test, columns=[['PCA1' , 'PCA2', 'interaction', 'quad_1', 'quad_2']])\n",
    "colors = ['r','c','b']\n",
    "label_text = [\"ALL Type T\", \"ALL Type B\", \"AHL\"]\n",
    "\n",
    "vec1 = x_test_1[:,0]\n",
    "vec2 = x_test_1[:,1]\n",
    "\n",
    "x1_range = vec1.max() - vec2.min()\n",
    "x2_range = vec1.max() - vec2.min()\n",
    "x1_min, x1_max = vec1.min()-0.1*x1_range, vec1.max() +0.1*x1_range\n",
    "x2_min, x2_max = vec2.min()-0.1*x2_range, vec2.max() + 0.1*x2_range\n",
    "\n",
    "step = .05 \n",
    "x1x, x2x = np.meshgrid(np.arange(x1_min, x1_max, step), np.arange(x2_min, x2_max, step))\n",
    "y_hat_multi = logit_ridge.predict(np.c_[x1x.ravel(), x2x.ravel()])\n",
    "\n",
    "plt.xlabel(\"PCA Dimension 1\")\n",
    "plt.ylabel(\"PCA Dimention 2\")\n",
    "plt.pcolormesh(x1x, x2x, y_hat_multi.reshape(x1x.shape), cmap=plt.cm.Paired,alpha = 0.5)\n",
    "for cur_quality in [0,1,2]:\n",
    "    cur_df = x_test_1[y2_test==cur_quality]\n",
    "    plt.scatter(cur_df[:,0], cur_df[:,1], c = colors[cur_quality], label=label_text[cur_quality], cmap=plt.cm.Paired)\n",
    "plt.legend();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec3 = x_test[:,0]\n",
    "vec4 = x_test[:,1]\n",
    "vec5 = x_test[:,2]\n",
    "vec6 = x_test[:,3]\n",
    "vec7 = x_test[:,4]\n",
    "\n",
    "x3_range = vec3.max() - vec3.min()\n",
    "x4_range = vec4.max() - vec4.min()\n",
    "x5_range = vec5.max() - vec5.min()\n",
    "x6_range = vec6.max() - vec6.min()\n",
    "x7_range = vec7.max() - vec7.min()\n",
    "\n",
    "\n",
    "x3_min, x3_max = vec3.min()-0.1*x3_range, vec3.max() +0.1*x3_range\n",
    "x4_min, x4_max = vec4.min()-0.1*x4_range, vec4.max() + 0.1*x4_range\n",
    "x5_min, x5_max = vec5.min()-0.1*x5_range, vec5.max() + 0.1*x5_range\n",
    "x6_min, x6_max = vec6.min()-0.1*x6_range, vec6.max() + 0.1*x6_range\n",
    "x7_min, x7_max = vec7.min()-0.1*x7_range, vec7.max() + 0.1*x7_range\n",
    "\n",
    "x3x, x4x = np.meshgrid(np.arange(x3_min, x3_max, step), np.arange(x4_min, x4_max, step))\n",
    "x5x = x3x**2\n",
    "x6x = x4x**2\n",
    "x7x = x3x * x4x\n",
    "y_hat_poly = logit_ridge_i.predict(np.c_[x3x.ravel(), x4x.ravel(), x5x.ravel(), x6x.ravel(), x7x.ravel()])\n",
    "\n",
    "#x1x\n",
    "#x2x\n",
    "#x1x**2\n",
    "\n",
    "\n",
    "plt.xlabel(\"PCA Dimension 1\")\n",
    "plt.ylabel(\"PCA Dimention 2\")\n",
    "plt.pcolormesh(x3x, x4x, y_hat_poly.reshape(x3x.shape), cmap=plt.cm.Paired,alpha = 0.5)\n",
    "# and we loop over the different groups\n",
    "for cur_quality in [0,1,2]:\n",
    "    cur_df = x_test[y2_test==cur_quality]\n",
    "    plt.scatter(cur_df[:,0], cur_df[:,1], c = colors[cur_quality], label=label_text[cur_quality], cmap=plt.cm.Paired)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using cross-validation to determine best number of principal components for multi-class prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using 2 PCs\n",
    "pca_2 = PCA(n_components=2).fit(x_train_scaled)\n",
    "x_train_pca_2 = pca_2.transform(x_train_scaled)\n",
    "x_test_pca_2 = pca_2.transform(x_test_scaled)\n",
    "\n",
    "print('Original dimensions:', x_train_scaled.shape)\n",
    "print('PCA dimensions:     ', x_train_pca_2.shape)\n",
    "\n",
    "#Training a logistic regression model\n",
    "logistic_pca_2 = LogisticRegressionCV(max_iter=500, cv=10, multi_class='multinomial').fit(x_train_pca_2, y2_train)\n",
    "\n",
    "#Predict\n",
    "y_pred_train = logistic_pca_2.predict(x_train_pca_2)\n",
    "y_pred_test = logistic_pca_2.predict(x_test_pca_2)\n",
    "\n",
    "#Perfromance Evaluation\n",
    "train_score = accuracy_score(y2_train, y_pred_train)*100\n",
    "test_score = accuracy_score(y2_test, y_pred_test)*100\n",
    "print(\"Training Set Accuracy:\",str(train_score)+'%')\n",
    "print(\"Testing Set Accuracy:\",str(test_score)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using 5 PCs\n",
    "pca_5 = PCA(n_components=5).fit(x_train_scaled)\n",
    "x_train_pca_2 = pca_5.transform(x_train_scaled)\n",
    "x_test_pca_2 = pca_5.transform(x_test_scaled)\n",
    "\n",
    "print('Original dimensions:', x_train_scaled.shape)\n",
    "print('PCA dimensions:     ', x_train_pca_2.shape)\n",
    "\n",
    "#Training a logistic regression model\n",
    "logistic_pca_2 = LogisticRegressionCV(max_iter=500, cv=10, multi_class='multinomial').fit(x_train_pca_2, y2_train)\n",
    "\n",
    "#Predict\n",
    "y_pred_train = logistic_pca_2.predict(x_train_pca_2)\n",
    "y_pred_test = logistic_pca_2.predict(x_test_pca_2)\n",
    "\n",
    "#Perfromance Evaluation\n",
    "train_score = accuracy_score(y2_train, y_pred_train)*100\n",
    "test_score = accuracy_score(y2_test, y_pred_test)*100\n",
    "print(\"Training Set Accuracy:\",str(train_score)+'%')\n",
    "print(\"Testing Set Accuracy:\",str(test_score)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using 10 PCs\n",
    "pca_10 = PCA(n_components=10).fit(x_train_scaled)\n",
    "x_train_pca_2 = pca_10.transform(x_train_scaled)\n",
    "x_test_pca_2 = pca_10.transform(x_test_scaled)\n",
    "\n",
    "print('Original dimensions:', x_train_scaled.shape)\n",
    "print('PCA dimensions:     ', x_train_pca_2.shape)\n",
    "\n",
    "#Training a logistic regression model\n",
    "logistic_pca_2 = LogisticRegressionCV(max_iter=500, cv=10, multi_class='multinomial').fit(x_train_pca_2, y2_train)\n",
    "\n",
    "#Predict\n",
    "y_pred_train = logistic_pca_2.predict(x_train_pca_2)\n",
    "y_pred_test = logistic_pca_2.predict(x_test_pca_2)\n",
    "\n",
    "#Perfromance Evaluation\n",
    "train_score = accuracy_score(y2_train, y_pred_train)*100\n",
    "test_score = accuracy_score(y2_test, y_pred_test)*100\n",
    "print(\"Training Set Accuracy:\",str(train_score)+'%')\n",
    "print(\"Testing Set Accuracy:\",str(test_score)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using 15 PCs\n",
    "pca_15 = PCA(n_components=15).fit(x_train_scaled)\n",
    "x_train_pca_2 = pca_15.transform(x_train_scaled)\n",
    "x_test_pca_2 = pca_15.transform(x_test_scaled)\n",
    "\n",
    "print('Original dimensions:', x_train_scaled.shape)\n",
    "print('PCA dimensions:     ', x_train_pca_2.shape)\n",
    "\n",
    "#Training a logistic regression model\n",
    "logistic_pca_2 = LogisticRegressionCV(max_iter=500, cv=10, multi_class='multinomial').fit(x_train_pca_2, y2_train)\n",
    "\n",
    "#Predict\n",
    "y_pred_train = logistic_pca_2.predict(x_train_pca_2)\n",
    "y_pred_test = logistic_pca_2.predict(x_test_pca_2)\n",
    "\n",
    "#Perfromance Evaluation\n",
    "train_score = accuracy_score(y2_train, y_pred_train)*100\n",
    "test_score = accuracy_score(y2_test, y_pred_test)*100\n",
    "print(\"Training Set Accuracy:\",str(train_score)+'%')\n",
    "print(\"Testing Set Accuracy:\",str(test_score)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using 20 PCs\n",
    "pca_20 = PCA(n_components=20).fit(x_train_scaled)\n",
    "x_train_pca_2 = pca_20.transform(x_train_scaled)\n",
    "x_test_pca_2 = pca_20.transform(x_test_scaled)\n",
    "\n",
    "print('Original dimensions:', x_train_scaled.shape)\n",
    "print('PCA dimensions:     ', x_train_pca_2.shape)\n",
    "\n",
    "#Training a logistic regression model\n",
    "logistic_pca_2 = LogisticRegressionCV(max_iter=500, cv=10, multi_class='multinomial').fit(x_train_pca_2, y2_train)\n",
    "\n",
    "#Predict\n",
    "y_pred_train = logistic_pca_2.predict(x_train_pca_2)\n",
    "y_pred_test = logistic_pca_2.predict(x_test_pca_2)\n",
    "\n",
    "#Perfromance Evaluation\n",
    "train_score = accuracy_score(y2_train, y_pred_train)*100\n",
    "test_score = accuracy_score(y2_test, y_pred_test)*100\n",
    "print(\"Training Set Accuracy:\",str(train_score)+'%')\n",
    "print(\"Testing Set Accuracy:\",str(test_score)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using 50 PCs\n",
    "pca_50 = PCA(n_components=50).fit(x_train_scaled)\n",
    "x_train_pca_2 = pca_50.transform(x_train_scaled)\n",
    "x_test_pca_2 = pca_50.transform(x_test_scaled)\n",
    "\n",
    "print('Original dimensions:', x_train_scaled.shape)\n",
    "print('PCA dimensions:     ', x_train_pca_2.shape)\n",
    "\n",
    "#Training a logistic regression model\n",
    "logistic_pca_2 = LogisticRegressionCV(max_iter=10000, cv=10, multi_class='multinomial').fit(x_train_pca_2, y2_train)\n",
    "\n",
    "#Predict\n",
    "y_pred_train = logistic_pca_2.predict(x_train_pca_2)\n",
    "y_pred_test = logistic_pca_2.predict(x_test_pca_2)\n",
    "\n",
    "#Perfromance Evaluation\n",
    "train_score = accuracy_score(y2_train, y_pred_train)*100\n",
    "test_score = accuracy_score(y2_test, y_pred_test)*100\n",
    "print(\"Training Set Accuracy:\",str(train_score)+'%')\n",
    "print(\"Testing Set Accuracy:\",str(test_score)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using 100 PCs\n",
    "pca_100 = PCA(n_components=100).fit(x_train_scaled)\n",
    "x_train_pca_2 = pca_100.transform(x_train_scaled)\n",
    "x_test_pca_2 = pca_100.transform(x_test_scaled)\n",
    "\n",
    "print('Original dimensions:', x_train_scaled.shape)\n",
    "print('PCA dimensions:     ', x_train_pca_2.shape)\n",
    "\n",
    "#Training a logistic regression model\n",
    "logistic_pca_2 = LogisticRegressionCV(max_iter=10000, cv=10, multi_class='multinomial').fit(x_train_pca_2, y2_train)\n",
    "\n",
    "#Predict\n",
    "y_pred_train = logistic_pca_2.predict(x_train_pca_2)\n",
    "y_pred_test = logistic_pca_2.predict(x_test_pca_2)\n",
    "\n",
    "#Perfromance Evaluation\n",
    "train_score = accuracy_score(y2_train, y_pred_train)*100\n",
    "test_score = accuracy_score(y2_test, y_pred_test)*100\n",
    "print(\"Training Set Accuracy:\",str(train_score)+'%')\n",
    "print(\"Testing Set Accuracy:\",str(test_score)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate classification accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_t = np.where(y2_test == 0)\n",
    "ALL_b = np.where(y2_test == 1)\n",
    "AHL = np.where(y2_test == 2)\n",
    "y2_test_2 = np.array(y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_t_test_score = accuracy_score(y2_test_2[ALL_t], y_pred_test[ALL_t])*100\n",
    "all_b_test_score = accuracy_score(y2_test_2[ALL_b], y_pred_test[ALL_b])*100\n",
    "ahl_test_score = accuracy_score(y2_test_2[AHL], y_pred_test[AHL])*100\n",
    "print(\"ALL T Accuracy:\",str(all_t_test_score)+'%')\n",
    "print(\"ALL B Accuracy:\",str(all_b_test_score)+'%')\n",
    "print(\"AHL Accuracy:\",str(ahl_test_score)+'%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
